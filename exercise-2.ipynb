{
  "cells":[
    {
      "cell_type":"code",
      "source":[
        "# models\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# data\n",
        "from sklearn.datasets import load_boston\n",
        "\n",
        "# analysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# others\n",
        "import pandas as pd\n",
        "from pandas import DataFrame"
      ],
      "execution_count":173,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def fit_predic(clf, x_test, x_train, y_test, y_train):\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred  = clf.predict(x_train)\n",
        "\n",
        "    error = 0\n",
        "    for i in range(len(y_train)):\n",
        "        error += (abs(y_train[i] - y_pred[i]) \/ y_train[i])\n",
        "    train_error_ridge = error \/ len(y_train) * 100\n",
        "\n",
        "    y_test = clf.predict(x_test)\n",
        "    y_predict = list(y_test)\n",
        "\n",
        "    error = 0\n",
        "    for i in range(len(y_test)):\n",
        "        error += (abs(y_pred[i] - y_test[i]) \/ y_pred[i])\n",
        "    test_error_ridge = error \/ len(y_test) * 100\n",
        "\n",
        "    \n",
        "    return train_error_ridge, test_error_ridge"
      ],
      "execution_count":174,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "boston = load_boston()\n",
        "X, y = boston.data, boston.target\n",
        "X_test, X_train, y_test, y_train = train_test_split(X, y, train_size=0.33)\n",
        "train_error = []\n",
        "test_error = []"
      ],
      "execution_count":175,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Linear Regression\n",
        "lnr_clf = LinearRegression()\n",
        "t = fit_predic(lnr_clf, X_test, X_train, y_test, y_train)\n",
        "train_error.append(t[0])\n",
        "test_error.append(t[1])"
      ],
      "execution_count":176,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Decision Tree Regressor\n",
        "dct_clf = DecisionTreeRegressor()\n",
        "t = fit_predic(dct_clf, X_test, X_train, y_test, y_train)\n",
        "train_error.append(t[0])\n",
        "test_error.append(t[1])"
      ],
      "execution_count":177,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# K-Neighbors Regressor\n",
        "knn_clf = KNeighborsRegressor()\n",
        "t = fit_predic(knn_clf, X_test, X_train, y_test, y_train)\n",
        "train_error.append(t[0])\n",
        "test_error.append(t[1])"
      ],
      "execution_count":178,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Voting Regressor\n",
        "voting_clf = VotingRegressor(estimators=[('ln', lnr_clf), ('dt', dct_clf), ('kn', knn_clf)])\n",
        "voting_clf.fit(X_train, y_train)\n",
        "predicts_train = []\n",
        "predicts_test = []\n",
        "for clf in (lnr_clf, dct_clf, knn_clf, voting_clf):\n",
        "    predicts_train.append(fit_predic(knn_clf, X_test, X_train, y_test, y_train)[0])\n",
        "    predicts_test.append(fit_predic(knn_clf, X_test, X_train, y_test, y_train)[1])\n",
        "\n",
        "train_error.append(sum(predicts_train) \/ len(predicts_train))\n",
        "test_error.append(sum(predicts_test) \/ len(predicts_test))"
      ],
      "execution_count":179,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# AdaBoost Regressor\n",
        "adb_clf = AdaBoostRegressor()\n",
        "t = fit_predic(adb_clf, X_test, X_train, y_test, y_train)\n",
        "train_error.append(t[0])\n",
        "test_error.append(t[1])"
      ],
      "execution_count":180,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Gradient Boosting Regressor\n",
        "xgb_clf = GradientBoostingRegressor()\n",
        "t = fit_predic(xgb_clf, X_test, X_train, y_test, y_train)\n",
        "train_error.append(t[0])\n",
        "test_error.append(t[1])"
      ],
      "execution_count":181,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Stacking Regressor\n",
        "stk_clf = StackingRegressor(estimators=[('ln', lnr_clf), ('dt', dct_clf), ('kn', knn_clf)])\n",
        "stk_clf.fit(X_train, y_train)\n",
        "predicts_train = []\n",
        "predicts_test = []\n",
        "for clf in (lnr_clf, dct_clf, knn_clf, voting_clf):\n",
        "    predicts_train.append(fit_predic(knn_clf, X_test, X_train, y_test, y_train)[0])\n",
        "    predicts_test.append(fit_predic(knn_clf, X_test, X_train, y_test, y_train)[1])\n",
        "\n",
        "train_error.append(sum(predicts_train) \/ len(predicts_train))\n",
        "test_error.append(sum(predicts_test) \/ len(predicts_test))"
      ],
      "execution_count":182,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "train_error"
      ],
      "execution_count":183,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "[16.92577749110088,\n",
              " 0.0,\n",
              " 16.97080442302114,\n",
              " 16.97080442302114,\n",
              " 12.326186719757045,\n",
              " 4.8471593935863355,\n",
              " 16.97080442302114]"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "test_error"
      ],
      "execution_count":184,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "[60.63117101417224,\n",
              " 50.05700483488592,\n",
              " 39.5828620896995,\n",
              " 39.5828620896995,\n",
              " 43.48410556056556,\n",
              " 49.43773851013985,\n",
              " 39.5828620896995]"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "col={'Train Error':train_error,'Test Error':test_error}\n",
        "models=['Linear Regression','Decision Tree Regressor','K-Neighbors Regressor','Voting Regressor','AdaBoost Regressor', 'Gradient Boosting Regressor', 'Stacking Regressor']\n",
        "df=DataFrame(data=col,index=models)\n",
        "df"
      ],
      "execution_count":185,
      "outputs":[
        {
          "data":{
            "text\/html":[
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "<\/style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th><\/th>\n",
              "      <th>Train Error<\/th>\n",
              "      <th>Test Error<\/th>\n",
              "    <\/tr>\n",
              "  <\/thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Linear Regression<\/th>\n",
              "      <td>16.925777<\/td>\n",
              "      <td>60.631171<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree Regressor<\/th>\n",
              "      <td>0.000000<\/td>\n",
              "      <td>50.057005<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>K-Neighbors Regressor<\/th>\n",
              "      <td>16.970804<\/td>\n",
              "      <td>39.582862<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>Voting Regressor<\/th>\n",
              "      <td>16.970804<\/td>\n",
              "      <td>39.582862<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost Regressor<\/th>\n",
              "      <td>12.326187<\/td>\n",
              "      <td>43.484106<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting Regressor<\/th>\n",
              "      <td>4.847159<\/td>\n",
              "      <td>49.437739<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>Stacking Regressor<\/th>\n",
              "      <td>16.970804<\/td>\n",
              "      <td>39.582862<\/td>\n",
              "    <\/tr>\n",
              "  <\/tbody>\n",
              "<\/table>\n",
              "<\/div>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}